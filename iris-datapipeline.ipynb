{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6570,"sourceType":"datasetVersion","datasetId":4247}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rajathiagaraj/iris-datapipeline?scriptVersionId=260493363\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# C1\n\nimport pandas as pd\n\n# Load the dataset with the correct file path.\n# Assumed file path, as per our previous discussion.\ndf = pd.read_csv('/kaggle/input/iriscsv/Iris.csv')\n\n# --- DEBUGGING STEP ---\n# Print the columns to see the exact names in the DataFrame\nprint(\"Columns in the DataFrame:\")\nprint(df.columns)\nprint(\"-\" * 20)\n\n# Once you have the correct name from the printout, use it here.\n# For example, if the output shows 'species' with a capital 'S',\n# you would change the code to:\n# cleaned_df = df.drop(columns=['Species'])\n\n# Based on the typical IRIS dataset, 'species' is the correct name,\n# so if it's giving you an error, it's very likely the dataset you're\n# using has a different column name.\n# Let's assume the name is 'Species' (capital 'S')\ntry:\n    cleaned_df = df.drop(columns=['species'])\nexcept KeyError:\n    # A more robust way to handle it if you're not sure of the case\n    print(\"Could not find 'species' column. Trying a case-insensitive match...\")\n    # Get all column names as a list\n    column_names = [col.lower() for col in df.columns]\n    # Find the index of the 'species' column, case-insensitive\n    if 'species' in column_names:\n        correct_col_name = df.columns[column_names.index('species')]\n        cleaned_df = df.drop(columns=[correct_col_name])\n        print(f\"Successfully dropped column '{correct_col_name}'.\")\n    else:\n        print(\"Error: The column 'species' was not found in the dataset, even with a case-insensitive search.\")\n        # You might want to stop the code here or handle it differently\n        # For now, let's re-raise the error to stop execution\n        raise\n\n# Save the new dataframe to a file\ncleaned_df.to_csv('cleaned_iris.csv', index=False)\n\nprint('Cleaned dataset saved successfully!')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:59:03.958541Z","iopub.execute_input":"2025-09-07T12:59:03.958844Z","iopub.status.idle":"2025-09-07T12:59:03.972793Z","shell.execute_reply.started":"2025-09-07T12:59:03.958822Z","shell.execute_reply":"2025-09-07T12:59:03.971963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# C2\nimport pandas as pd\n\n# Load a file from the read-only input directory\ndf = pd.read_csv('/kaggle/input/iriscsv/Iris.csv')\n\n# ... do some data processing ...\n# Let's say we just want to save the head of the dataframe\ndf_head = df.head()\n\n# Save the new file to the writable working directory\noutput_file_path = '/kaggle/working/iris_head.csv'\ndf_head.to_csv(output_file_path, index=False)\n\nprint(f\"File saved to: {output_file_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:00:49.116075Z","iopub.execute_input":"2025-09-07T13:00:49.116416Z","iopub.status.idle":"2025-09-07T13:00:49.128792Z","shell.execute_reply.started":"2025-09-07T13:00:49.116393Z","shell.execute_reply":"2025-09-07T13:00:49.127947Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Summary of Error Rectification in a Kaggle Notebook\n\nThis notebook serves as a log for common errors encountered when working with datasets on Kaggle and the methods used to resolve them. The key to successful debugging is understanding the specifics of the Kaggle environment.\n\n---\n\n#### 1. `IsADirectoryError`\n\n**The Error:** `IsADirectoryError: [Errno 21] Is a directory: '/kaggle/input/iris-flower-dataset'`\n\n**The Problem:** This error occurs when a directory is treated as a file. The path `/kaggle/input/iris-flower-dataset` points to a folder, not a file itself. A DataFrame cannot be created from a folder.\n\n**The Solution:** The file needs to be explicitly specified within the directory. By inspecting the dataset's contents (via the `Data` panel or the `!ls` command), we found the correct file name (`IRIS.csv`).\n\n**Corrected Code:**\n```python\nimport pandas as pd\ndf = pd.read_csv('/kaggle/input/iris-flower-dataset/IRIS.csv')","metadata":{}},{"cell_type":"markdown","source":"2. KeyError\nThe Error: KeyError: \"['species'] not found in axis\"\n\nThe Problem: This error means that a column with the exact name 'species' does not exist in the DataFrame. This is typically due to a case-sensitivity issue or a slight spelling difference.\n\nThe Solution: The best way to resolve this is to inspect the DataFrame's columns immediately after loading the data. The command df.columns reveals the exact column names. In this case, the column was capitalized as 'Species'.\n\nDebugging Code:\n\nPython\n\nprint(\"Columns in the DataFrame:\")\nprint(df.columns)\nCorrected Code (using the correct capitalization):\n\nPython\n\ncleaned_df = df.drop(columns=['Species'])","metadata":{}},{"cell_type":"markdown","source":"3. FileNotFoundError\nThe Error: FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/iris-flower-dataset/IRIS.csv'\n\nThe Problem: This is a common issue when a new notebook session starts. The environment resets, and the previously attached datasets are temporarily disconnected. The file path becomes invalid until the dataset is re-attached.\n\nThe Solution: The dataset must be re-added to the notebook via the Kaggle UI. In the \"Data\" panel on the right, click \"+ Add data\" and select the required dataset. This action remounts the files, making them accessible at the /kaggle/input/ path.","metadata":{}},{"cell_type":"markdown","source":"Key Takeaways and Best Practices\nKnow Your Directories: Always use /kaggle/input/ for reading datasets and /kaggle/working/ for writing output files. /kaggle/input/ is read-only, while /kaggle/working/ is read-write.\n\nInspect Your Data: Use df.columns to verify column names and !ls to check for files within a directory.\n\nSession Management: Be aware that starting a new session requires re-attaching datasets. Running all cells (Run > Run All) is a good practice to ensure the environment is correctly set up from the start.\n\nCommitting: Committing the notebook with \"Save & Run All\" is crucial for saving your output and creating a reproducible record of your work.","metadata":{}}]}